{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T15:46:05.876096Z",
     "start_time": "2019-05-13T15:46:05.855290Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pan19_cdaa_evaluator import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:10:57.731354Z",
     "start_time": "2019-05-13T13:10:57.721327Z"
    }
   },
   "outputs": [],
   "source": [
    "# get current directory\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T13:10:57.749403Z",
     "start_time": "2019-05-13T13:10:57.737370Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_files(path: str, label: str):\n",
    "    # Reads all text files located in the 'path' and assigns them to 'label' class\n",
    "    files = glob.glob(path+os.sep+label+os.sep+'*.txt')\n",
    "    texts=[]\n",
    "    for i,v in enumerate(files):\n",
    "        f=codecs.open(v,'r',encoding='utf-8')\n",
    "        texts.append((f.read(),label))\n",
    "        f.close()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:06:58.125796Z",
     "start_time": "2019-05-13T16:06:58.117775Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def regex(string: str, model: str):\n",
    "    \"\"\"\n",
    "    Function that computes regular expressions.\n",
    "    \"\"\"\n",
    "    string = re.sub(\"[0-9]\", \"0\", string) # each digit will be represented as a 0\n",
    "    string = re.sub(r'( \\n| \\t)+', '', string)\n",
    "    #text = re.sub(\"[0-9]+(([.,^])[0-9]+)?\", \"#\", text)\n",
    "    string = re.sub(\"https:\\\\\\+([a-zA-Z0-9.]+)?\", \"@\", string)\n",
    "    \n",
    "    if model == 'word':\n",
    "        # if model is a word n-gram model, remove all punctuation\n",
    "        string = ''.join([char for char in string if char.isalnum()])\n",
    "        \n",
    "    if model == 'char-dist':\n",
    "        string = re.sub(\"[a-zA-Z]+\", \"*\", string)\n",
    "        # string = ''.join(['*' if char.isalpha() else char for char in string])\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:06:58.816839Z",
     "start_time": "2019-05-13T16:06:58.812828Z"
    }
   },
   "outputs": [],
   "source": [
    "def frequency(tokens: list):\n",
    "    \"\"\"\n",
    "    Count tokens in text (keys are tokens, values are their corresponding frequencies).\n",
    "    \"\"\"\n",
    "    freq = dict()\n",
    "    for token in tokens:\n",
    "        if token in freq:\n",
    "            freq[token] += 1\n",
    "        else:\n",
    "            freq[token] = 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:06:59.215900Z",
     "start_time": "2019-05-13T16:06:59.204871Z"
    }
   },
   "outputs": [],
   "source": [
    "def represent_text(text, n: int, model: str):\n",
    "    \"\"\"\n",
    "    Extracts all character or word 'n'-grams from a given 'text'.\n",
    "    Any digit is represented through a 0.\n",
    "    Each hyperlink is replaced by an @ sign.\n",
    "    The latter steps are computed through regular expressions.\n",
    "    \"\"\" \n",
    "    if model == 'char-std' or model == 'char-dist':\n",
    "\n",
    "        text = regex(text, model)\n",
    "        tokens = [text[i:i+n] for i in range(len(text)-n+1)] \n",
    "\n",
    "        if model == 'char-std' and n == 2:\n",
    "            # create list of unigrams that only consists of punctuation marks\n",
    "            # and extend tokens by that list\n",
    "            punct_unigrams = [token for token in text if not token.isalnum()]\n",
    "            tokens.extend(punct_unigrams)\n",
    "\n",
    "    elif model == 'word':\n",
    "        text = [regex(word, model) for word in text.split() if regex(word, model)]\n",
    "        tokens = [' '.join(text[i:i+n]) for i in range(len(text)-n+1)]\n",
    "    \n",
    "    freq = frequency(tokens)\n",
    "\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:06:59.646269Z",
     "start_time": "2019-05-13T16:06:59.638249Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_vocabulary(texts: list, n: int, ft: int, model: str):\n",
    "    \"\"\"\n",
    "    Extracts all character 'n'-grams occurring at least 'ft' times in a set of 'texts'.\n",
    "    \"\"\"\n",
    "    occurrences = {}\n",
    "    \n",
    "    for text in texts:\n",
    "\n",
    "        text_occurrences=represent_text(text, n, model)\n",
    "        \n",
    "        for ngram in text_occurrences.keys():\n",
    "            \n",
    "            if ngram in occurrences:\n",
    "                occurrences[ngram] += text_occurrences[ngram]\n",
    "            else:\n",
    "                occurrences[ngram] = text_occurrences[ngram]\n",
    "    \n",
    "    vocabulary=[]\n",
    "    for i in occurrences.keys():\n",
    "        if occurrences[i] >= ft:\n",
    "            vocabulary.append(i)\n",
    "            \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:07:00.365084Z",
     "start_time": "2019-05-13T16:07:00.359069Z"
    }
   },
   "outputs": [],
   "source": [
    "def extend_vocabulary(n_range: tuple, texts: list, model: str):\n",
    "    n_start, n_end = n_range\n",
    "    vocab = []\n",
    "    for n in range(n_start, n_end + 1):\n",
    "        n_vocab = extract_vocabulary(texts, n, (n_end - n) + 1, model)\n",
    "        vocab.extend(n_vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:07:01.602261Z",
     "start_time": "2019-05-13T16:07:01.541098Z"
    }
   },
   "outputs": [],
   "source": [
    "def baseline(path, outpath, word_range: tuple, dist_range: tuple, char_range: tuple, pt = 0.1, n_best_factor = 0.5, \n",
    "             lower = False, use_LSA = False):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Reading information about the collection\n",
    "    infocollection = path+os.sep+'collection-info.json'\n",
    "    problems = []\n",
    "    language = []\n",
    "    \n",
    "    with open(infocollection, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            problems.append(attrib['problem-name'])\n",
    "            language.append(attrib['language'])\n",
    "                \n",
    "    for index, problem in enumerate(problems):\n",
    "        print(problem)\n",
    "        # Reading information about the problem\n",
    "        infoproblem = path+os.sep+problem+os.sep+'problem-info.json'\n",
    "        candidates = []\n",
    "        with open(infoproblem, 'r') as f:\n",
    "            fj = json.load(f)\n",
    "            unk_folder = fj['unknown-folder']\n",
    "            for attrib in fj['candidate-authors']:\n",
    "                candidates.append(attrib['author-name'])\n",
    "                \n",
    "        # building training set\n",
    "        train_docs = []\n",
    "        for candidate in candidates:\n",
    "            train_docs.extend(read_files(path+os.sep+problem,candidate))\n",
    "            \n",
    "        train_texts = [text for (text,label) in train_docs]        \n",
    "        train_labels = [label for (text,label) in train_docs]\n",
    "        \n",
    "        # word n-gram vocabulary (content / semantical features)\n",
    "        vocab_word = extend_vocabulary(word_range, train_texts, model = 'word')\n",
    "        \n",
    "        # character n-gram vocabulary (non-diacrictics / alphabetical symbols are distorted)\n",
    "        vocab_char_dist = extend_vocabulary(dist_range, train_texts, model = 'char-dist')\n",
    "        \n",
    "        # character n-gram vocabulary (syntactical features)\n",
    "        vocab_char_std = extend_vocabulary(char_range, train_texts, model = 'char-std')\n",
    "        \n",
    "        print('\\t', 'language: ', language[index])\n",
    "        print('\\t', len(candidates), 'candidate authors')\n",
    "        print('\\t', len(train_texts), 'known texts')\n",
    "        \n",
    "        print('\\t', 'word-based vocabulary size:', len(vocab_word))\n",
    "        print('\\t', 'standard character vocabulary size:', len(vocab_char_std))\n",
    "        print('\\t', 'non-alphabetical character vocabulary size:', len(vocab_char_dist))\n",
    "\n",
    "        \n",
    "        # building test set\n",
    "        test_docs = read_files(path+os.sep+problem,unk_folder)\n",
    "        test_texts = [text for (text,label) in test_docs]\n",
    "        \n",
    "        ## initialize tf-idf vectorizer for word n-gram model (captures content) ##\n",
    "        vectorizer_word = TfidfVectorizer(analyzer = 'word', ngram_range = word_range, use_idf = True, \n",
    "                                          norm = 'l2', lowercase = lower, vocabulary = vocab_word, \n",
    "                                          smooth_idf = True, sublinear_tf = True)\n",
    "\n",
    "        train_data_word = vectorizer_word.fit_transform(train_texts).toarray()\n",
    "\n",
    "        n_best = int(len(vectorizer_word.idf_) * n_best_factor)\n",
    "        idx_w = np.argsort(vectorizer_word.idf_)[:n_best]\n",
    "\n",
    "        train_data_word = train_data_word[:, idx_w]\n",
    "\n",
    "        test_data_word = vectorizer_word.transform(test_texts).toarray()\n",
    "        test_data_word = test_data_word[:, idx_w]\n",
    "        \n",
    "        ## initialize tf-idf vectorizer for char n-gram model in which non-diacritics are distorted ##\n",
    "        \n",
    "        vectorizer_char_dist = TfidfVectorizer(analyzer = 'char', ngram_range = dist_range, use_idf = True, \n",
    "                                     norm = 'l2', lowercase = lower, vocabulary = vocab_char_dist, \n",
    "                                     min_df = 0.1, max_df = 0.8, smooth_idf = True, \n",
    "                                     sublinear_tf = True)\n",
    "\n",
    "        train_data_char_dist = vectorizer_char_dist.fit_transform(train_texts).toarray()\n",
    "\n",
    "        n_best = int(len(vectorizer_char_dist.idf_) * n_best_factor)\n",
    "        idx_c = np.argsort(vectorizer_char_dist.idf_)[:n_best]\n",
    "\n",
    "        train_data_char_dist = train_data_char_dist[:, idx_c]\n",
    "\n",
    "        test_data_char_dist = vectorizer_char_dist.transform(test_texts).toarray()\n",
    "        test_data_char_dist = test_data_char_dist[:, idx_c]\n",
    "        \n",
    "        ##  initialize tf-idf vectorizer for char n-gram model (captures syntactical features) ##\n",
    "        vectorizer_char_std = TfidfVectorizer(analyzer = 'char', ngram_range = char_range, use_idf = True, \n",
    "                                     norm = 'l2', lowercase = lower, vocabulary = vocab_char_std, \n",
    "                                     min_df = 0.1, max_df = 0.8, smooth_idf = True, \n",
    "                                     sublinear_tf = True)\n",
    "\n",
    "        train_data_char_std = vectorizer_char_std.fit_transform(train_texts).toarray()\n",
    "\n",
    "        n_best = int(len(vectorizer_char_std.idf_) * n_best_factor)\n",
    "        idx_c = np.argsort(vectorizer_char_std.idf_)[:n_best]\n",
    "\n",
    "        train_data_char_std = train_data_char_std[:, idx_c]\n",
    "\n",
    "        test_data_char_std = vectorizer_char_std.transform(test_texts).toarray()\n",
    "        test_data_char_std = test_data_char_std[:, idx_c]\n",
    "        \n",
    "        print('\\t', len(test_texts), 'unknown texts')\n",
    "        \n",
    "        max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "        \n",
    "        ## scale text data for word n-gram model ##\n",
    "        scaled_train_data_word = max_abs_scaler.fit_transform(train_data_word)\n",
    "        scaled_test_data_word = max_abs_scaler.transform(test_data_word)\n",
    "        \n",
    "        ## scale text data for char dist n-gram model ##\n",
    "        scaled_train_data_char_dist = max_abs_scaler.fit_transform(train_data_char_dist)\n",
    "        scaled_test_data_char_dist = max_abs_scaler.transform(test_data_char_dist)\n",
    "        \n",
    "         ## scale text data for char std n-gram model ##\n",
    "        scaled_train_data_char_std = max_abs_scaler.fit_transform(train_data_char_std)\n",
    "        scaled_test_data_char_std = max_abs_scaler.transform(test_data_char_std)\n",
    "        \n",
    "        if use_LSA:\n",
    "            \n",
    "            # initialize truncated singular value decomposition\n",
    "            svd = TruncatedSVD(n_components = 63, algorithm = 'randomized', random_state = 42)    \n",
    "            \n",
    "            # Word\n",
    "            scaled_train_data_word = svd.fit_transform(scaled_train_data_word)\n",
    "            scaled_test_data_word = svd.transform(scaled_test_data_word)\n",
    "\n",
    "            # Dist\n",
    "            scaled_train_data_char_dist = svd.fit_transform(scaled_train_data_char_dist)\n",
    "            scaled_test_data_char_dist = svd.transform(scaled_test_data_char_dist)\n",
    "\n",
    "            # Char\n",
    "            scaled_train_data_char_std = svd.fit_transform(scaled_train_data_char_std)\n",
    "            scaled_test_data_char_std = svd.transform(scaled_test_data_char_std)\n",
    "        \n",
    "        word = CalibratedClassifierCV(OneVsRestClassifier(SVC(C = 1, kernel = 'linear', \n",
    "                                                              gamma = 'auto')))\n",
    "        word.fit(scaled_train_data_word, train_labels)\n",
    "        preds_word = word.predict(scaled_test_data_word)\n",
    "        probas_word = word.predict_proba(scaled_test_data_word)\n",
    "        \n",
    "        char_dist = CalibratedClassifierCV(OneVsRestClassifier(SVC(C = 1, kernel = 'linear', \n",
    "                                                                   gamma = 'auto')))\n",
    "        char_dist.fit(scaled_train_data_char_dist, train_labels)\n",
    "        preds_dist = char_dist.predict(scaled_test_data_char_dist)\n",
    "        probas_dist = char_dist.predict_proba(scaled_test_data_char_dist)\n",
    "        \n",
    "        char_std = CalibratedClassifierCV(OneVsRestClassifier(SVC(C = 1, kernel = 'linear', \n",
    "                                                                  gamma = 'auto')))\n",
    "        char_std.fit(scaled_train_data_char_std, train_labels)\n",
    "        preds_char = char_std.predict(scaled_test_data_char_std)\n",
    "        probas_char = char_std.predict_proba(scaled_test_data_char_std)\n",
    "        \n",
    "        # Soft Voting procedure (combines the votes of the three individual classifier)\n",
    "        avg_probas = np.average([probas_word, probas_dist, probas_char], axis = 0)        \n",
    "        avg_predictions = []\n",
    "        for text_probs in avg_probas:\n",
    "            ind_best = np.argmax(text_probs)\n",
    "            avg_predictions.append(candidates[ind_best])\n",
    "\n",
    "        # Reject option (used in open-set cases)\n",
    "        count=0\n",
    "        for i,p in enumerate(avg_predictions):\n",
    "            sproba=sorted(avg_probas[i],reverse=True)\n",
    "            if sproba[0]-sproba[1] < pt or max(sproba) < 0.25:\n",
    "                avg_predictions[i]=u'<UNK>'\n",
    "                count=count+1\n",
    "        print('\\t',count,'texts left unattributed')\n",
    "        \n",
    "        # Saving output data\n",
    "        out_data=[]\n",
    "        unk_filelist = glob.glob(path+os.sep+problem+os.sep+unk_folder+os.sep+'*.txt')\n",
    "        pathlen=len(path+os.sep+problem+os.sep+unk_folder+os.sep)\n",
    "        \n",
    "        for i,v in enumerate(avg_predictions):\n",
    "            out_data.append({'unknown-text': unk_filelist[i][pathlen:], 'predicted-author': v})\n",
    "            \n",
    "        with open(outpath+os.sep+'answers-'+problem+'.json', 'w') as f:\n",
    "            json.dump(out_data, f, indent=4)\n",
    "        print('\\t', 'answers saved to file','answers-'+problem+'.json')\n",
    "        \n",
    "    print('elapsed time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:10:27.742839Z",
     "start_time": "2019-05-13T16:07:04.300459Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem00001\n",
      "\t language:  en\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 53667\n",
      "\t standard character vocabulary size: 85703\n",
      "\t non-alphabetical character vocabulary size: 659\n",
      "\t 561 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 104 texts left unattributed\n",
      "\t answers saved to file answers-problem00001.json\n",
      "problem00002\n",
      "\t language:  en\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 54699\n",
      "\t standard character vocabulary size: 84546\n",
      "\t non-alphabetical character vocabulary size: 637\n",
      "\t 137 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 60 texts left unattributed\n",
      "\t answers saved to file answers-problem00002.json\n",
      "problem00003\n",
      "\t language:  en\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 52153\n",
      "\t standard character vocabulary size: 83414\n",
      "\t non-alphabetical character vocabulary size: 712\n",
      "\t 211 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 105 texts left unattributed\n",
      "\t answers saved to file answers-problem00003.json\n",
      "problem00004\n",
      "\t language:  en\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 52832\n",
      "\t standard character vocabulary size: 87809\n",
      "\t non-alphabetical character vocabulary size: 721\n",
      "\t 273 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 158 texts left unattributed\n",
      "\t answers saved to file answers-problem00004.json\n",
      "problem00005\n",
      "\t language:  en\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 53950\n",
      "\t standard character vocabulary size: 82383\n",
      "\t non-alphabetical character vocabulary size: 623\n",
      "\t 264 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 109 texts left unattributed\n",
      "\t answers saved to file answers-problem00005.json\n",
      "problem00006\n",
      "\t language:  fr\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 51022\n",
      "\t standard character vocabulary size: 81084\n",
      "\t non-alphabetical character vocabulary size: 969\n",
      "\t 121 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 32 texts left unattributed\n",
      "\t answers saved to file answers-problem00006.json\n",
      "problem00007\n",
      "\t language:  fr\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 51210\n",
      "\t standard character vocabulary size: 81740\n",
      "\t non-alphabetical character vocabulary size: 1107\n",
      "\t 92 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 33 texts left unattributed\n",
      "\t answers saved to file answers-problem00007.json\n",
      "problem00008\n",
      "\t language:  fr\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 50152\n",
      "\t standard character vocabulary size: 85185\n",
      "\t non-alphabetical character vocabulary size: 1162\n",
      "\t 430 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 180 texts left unattributed\n",
      "\t answers saved to file answers-problem00008.json\n",
      "problem00009\n",
      "\t language:  fr\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 50307\n",
      "\t standard character vocabulary size: 81966\n",
      "\t non-alphabetical character vocabulary size: 960\n",
      "\t 239 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 143 texts left unattributed\n",
      "\t answers saved to file answers-problem00009.json\n",
      "problem00010\n",
      "\t language:  fr\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 50154\n",
      "\t standard character vocabulary size: 83877\n",
      "\t non-alphabetical character vocabulary size: 1032\n",
      "\t 38 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 22 texts left unattributed\n",
      "\t answers saved to file answers-problem00010.json\n",
      "problem00011\n",
      "\t language:  it\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 55050\n",
      "\t standard character vocabulary size: 86177\n",
      "\t non-alphabetical character vocabulary size: 1116\n",
      "\t 139 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 63 texts left unattributed\n",
      "\t answers saved to file answers-problem00011.json\n",
      "problem00012\n",
      "\t language:  it\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 54715\n",
      "\t standard character vocabulary size: 83815\n",
      "\t non-alphabetical character vocabulary size: 937\n",
      "\t 116 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 39 texts left unattributed\n",
      "\t answers saved to file answers-problem00012.json\n",
      "problem00013\n",
      "\t language:  it\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 54103\n",
      "\t standard character vocabulary size: 78772\n",
      "\t non-alphabetical character vocabulary size: 967\n",
      "\t 196 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 70 texts left unattributed\n",
      "\t answers saved to file answers-problem00013.json\n",
      "problem00014\n",
      "\t language:  it\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 54987\n",
      "\t standard character vocabulary size: 83066\n",
      "\t non-alphabetical character vocabulary size: 1073\n",
      "\t 46 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 15 texts left unattributed\n",
      "\t answers saved to file answers-problem00014.json\n",
      "problem00015\n",
      "\t language:  it\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 55003\n",
      "\t standard character vocabulary size: 85154\n",
      "\t non-alphabetical character vocabulary size: 1058\n",
      "\t 54 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 25 texts left unattributed\n",
      "\t answers saved to file answers-problem00015.json\n",
      "problem00016\n",
      "\t language:  sp\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 57325\n",
      "\t standard character vocabulary size: 84536\n",
      "\t non-alphabetical character vocabulary size: 1076\n",
      "\t 164 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 38 texts left unattributed\n",
      "\t answers saved to file answers-problem00016.json\n",
      "problem00017\n",
      "\t language:  sp\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 56881\n",
      "\t standard character vocabulary size: 88031\n",
      "\t non-alphabetical character vocabulary size: 1100\n",
      "\t 112 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 50 texts left unattributed\n",
      "\t answers saved to file answers-problem00017.json\n",
      "problem00018\n",
      "\t language:  sp\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 56419\n",
      "\t standard character vocabulary size: 82861\n",
      "\t non-alphabetical character vocabulary size: 1144\n",
      "\t 238 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 77 texts left unattributed\n",
      "\t answers saved to file answers-problem00018.json\n",
      "problem00019\n",
      "\t language:  sp\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 55713\n",
      "\t standard character vocabulary size: 82986\n",
      "\t non-alphabetical character vocabulary size: 996\n",
      "\t 450 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 203 texts left unattributed\n",
      "\t answers saved to file answers-problem00019.json\n",
      "problem00020\n",
      "\t language:  sp\n",
      "\t 9 candidate authors\n",
      "\t 63 known texts\n",
      "\t word-based vocabulary size: 55811\n",
      "\t standard character vocabulary size: 81896\n",
      "\t non-alphabetical character vocabulary size: 1105\n",
      "\t 170 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 113 texts left unattributed\n",
      "\t answers saved to file answers-problem00020.json\n",
      "elapsed time: 203.40237283706665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "baseline(cwd + \"\\\\cross-domain-authorship-attribution-train\", cwd + '\\\\answers', word_range = (1,3), dist_range = (1,3), char_range = (2,5), use_LSA = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:10:27.926325Z",
     "start_time": "2019-05-13T16:10:27.796982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem00001 Macro-F1: 0.857\n",
      "problem00002 Macro-F1: 0.56\n",
      "problem00003 Macro-F1: 0.719\n",
      "problem00004 Macro-F1: 0.559\n",
      "problem00005 Macro-F1: 0.582\n",
      "problem00006 Macro-F1: 0.793\n",
      "problem00007 Macro-F1: 0.622\n",
      "problem00008 Macro-F1: 0.643\n",
      "problem00009 Macro-F1: 0.732\n",
      "problem00010 Macro-F1: 0.621\n",
      "problem00011 Macro-F1: 0.757\n",
      "problem00012 Macro-F1: 0.683\n",
      "problem00013 Macro-F1: 0.784\n",
      "problem00014 Macro-F1: 0.873\n",
      "problem00015 Macro-F1: 0.775\n",
      "problem00016 Macro-F1: 0.83\n",
      "problem00017 Macro-F1: 0.723\n",
      "problem00018 Macro-F1: 0.842\n",
      "problem00019 Macro-F1: 0.683\n",
      "problem00020 Macro-F1: 0.453\n",
      "Overall score: 0.705\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(\"cross-domain-authorship-attribution-train\", \"answers\", \"evaluation\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
